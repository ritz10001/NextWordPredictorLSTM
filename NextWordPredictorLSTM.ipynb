{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWzxqvnV2bgdaVT01epkfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritz10001/NextWordPredictorLSTM/blob/main/NextWordPredictorLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cZ6sKdt629M"
      },
      "outputs": [],
      "source": [
        "train_text = \"\"\"The quick brown fox jumps over the lazy dog.\n",
        "I love programming and solving complex problems.\n",
        "Artificial intelligence is transforming the world.\n",
        "It's a beautiful day to learn something new.\n",
        "Data science involves statistics, coding, and domain knowledge.\n",
        "Natural language processing is a fascinating field.\n",
        "Machine learning models improve with more data.\n",
        "Python is a versatile and popular programming language.\n",
        "Deep learning algorithms require a lot of computational power.\n",
        "The weather is sunny and warm today.\n",
        "She sells seashells by the seashore.\n",
        "Reading books expands your knowledge and imagination.\n",
        "Exercise is important for maintaining good health.\n",
        "He enjoys hiking in the mountains on weekends.\n",
        "Music can have a profound effect on your emotions.\n",
        "The cat sat on the mat and looked out the window.\n",
        "He built a robot that can navigate obstacles autonomously.\n",
        "Her favorite hobby is painting landscapes.\n",
        "Technology is advancing at a rapid pace.\n",
        "They traveled to many countries during their vacation.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "2MTFJgUo7Qsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "YJUWpWE07fjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([train_text])"
      ],
      "metadata": {
        "id": "ChdK5-0D7kS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e9WpAIW7nQl",
        "outputId": "864d365f-988b-462a-9fb8-242e202addc8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'a': 3,\n",
              " 'and': 4,\n",
              " 'on': 5,\n",
              " 'programming': 6,\n",
              " 'to': 7,\n",
              " 'data': 8,\n",
              " 'knowledge': 9,\n",
              " 'language': 10,\n",
              " 'learning': 11,\n",
              " 'your': 12,\n",
              " 'he': 13,\n",
              " 'can': 14,\n",
              " 'quick': 15,\n",
              " 'brown': 16,\n",
              " 'fox': 17,\n",
              " 'jumps': 18,\n",
              " 'over': 19,\n",
              " 'lazy': 20,\n",
              " 'dog': 21,\n",
              " 'i': 22,\n",
              " 'love': 23,\n",
              " 'solving': 24,\n",
              " 'complex': 25,\n",
              " 'problems': 26,\n",
              " 'artificial': 27,\n",
              " 'intelligence': 28,\n",
              " 'transforming': 29,\n",
              " 'world': 30,\n",
              " \"it's\": 31,\n",
              " 'beautiful': 32,\n",
              " 'day': 33,\n",
              " 'learn': 34,\n",
              " 'something': 35,\n",
              " 'new': 36,\n",
              " 'science': 37,\n",
              " 'involves': 38,\n",
              " 'statistics': 39,\n",
              " 'coding': 40,\n",
              " 'domain': 41,\n",
              " 'natural': 42,\n",
              " 'processing': 43,\n",
              " 'fascinating': 44,\n",
              " 'field': 45,\n",
              " 'machine': 46,\n",
              " 'models': 47,\n",
              " 'improve': 48,\n",
              " 'with': 49,\n",
              " 'more': 50,\n",
              " 'python': 51,\n",
              " 'versatile': 52,\n",
              " 'popular': 53,\n",
              " 'deep': 54,\n",
              " 'algorithms': 55,\n",
              " 'require': 56,\n",
              " 'lot': 57,\n",
              " 'of': 58,\n",
              " 'computational': 59,\n",
              " 'power': 60,\n",
              " 'weather': 61,\n",
              " 'sunny': 62,\n",
              " 'warm': 63,\n",
              " 'today': 64,\n",
              " 'she': 65,\n",
              " 'sells': 66,\n",
              " 'seashells': 67,\n",
              " 'by': 68,\n",
              " 'seashore': 69,\n",
              " 'reading': 70,\n",
              " 'books': 71,\n",
              " 'expands': 72,\n",
              " 'imagination': 73,\n",
              " 'exercise': 74,\n",
              " 'important': 75,\n",
              " 'for': 76,\n",
              " 'maintaining': 77,\n",
              " 'good': 78,\n",
              " 'health': 79,\n",
              " 'enjoys': 80,\n",
              " 'hiking': 81,\n",
              " 'in': 82,\n",
              " 'mountains': 83,\n",
              " 'weekends': 84,\n",
              " 'music': 85,\n",
              " 'have': 86,\n",
              " 'profound': 87,\n",
              " 'effect': 88,\n",
              " 'emotions': 89,\n",
              " 'cat': 90,\n",
              " 'sat': 91,\n",
              " 'mat': 92,\n",
              " 'looked': 93,\n",
              " 'out': 94,\n",
              " 'window': 95,\n",
              " 'built': 96,\n",
              " 'robot': 97,\n",
              " 'that': 98,\n",
              " 'navigate': 99,\n",
              " 'obstacles': 100,\n",
              " 'autonomously': 101,\n",
              " 'her': 102,\n",
              " 'favorite': 103,\n",
              " 'hobby': 104,\n",
              " 'painting': 105,\n",
              " 'landscapes': 106,\n",
              " 'technology': 107,\n",
              " 'advancing': 108,\n",
              " 'at': 109,\n",
              " 'rapid': 110,\n",
              " 'pace': 111,\n",
              " 'they': 112,\n",
              " 'traveled': 113,\n",
              " 'many': 114,\n",
              " 'countries': 115,\n",
              " 'during': 116,\n",
              " 'their': 117,\n",
              " 'vacation': 118}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for sentence in train_text.split('\\n'):\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(tokenized_sentence)):\n",
        "        input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "K695kqN-7z2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-bDuzDR-49B",
        "outputId": "b482441a-37b7-45cb-ed88-7b75426e83f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 15],\n",
              " [1, 15, 16],\n",
              " [1, 15, 16, 17],\n",
              " [1, 15, 16, 17, 18],\n",
              " [1, 15, 16, 17, 18, 19],\n",
              " [1, 15, 16, 17, 18, 19, 1],\n",
              " [1, 15, 16, 17, 18, 19, 1, 20],\n",
              " [1, 15, 16, 17, 18, 19, 1, 20, 21],\n",
              " [22, 23],\n",
              " [22, 23, 6],\n",
              " [22, 23, 6, 4],\n",
              " [22, 23, 6, 4, 24],\n",
              " [22, 23, 6, 4, 24, 25],\n",
              " [22, 23, 6, 4, 24, 25, 26],\n",
              " [27, 28],\n",
              " [27, 28, 2],\n",
              " [27, 28, 2, 29],\n",
              " [27, 28, 2, 29, 1],\n",
              " [27, 28, 2, 29, 1, 30],\n",
              " [31, 3],\n",
              " [31, 3, 32],\n",
              " [31, 3, 32, 33],\n",
              " [31, 3, 32, 33, 7],\n",
              " [31, 3, 32, 33, 7, 34],\n",
              " [31, 3, 32, 33, 7, 34, 35],\n",
              " [31, 3, 32, 33, 7, 34, 35, 36],\n",
              " [8, 37],\n",
              " [8, 37, 38],\n",
              " [8, 37, 38, 39],\n",
              " [8, 37, 38, 39, 40],\n",
              " [8, 37, 38, 39, 40, 4],\n",
              " [8, 37, 38, 39, 40, 4, 41],\n",
              " [8, 37, 38, 39, 40, 4, 41, 9],\n",
              " [42, 10],\n",
              " [42, 10, 43],\n",
              " [42, 10, 43, 2],\n",
              " [42, 10, 43, 2, 3],\n",
              " [42, 10, 43, 2, 3, 44],\n",
              " [42, 10, 43, 2, 3, 44, 45],\n",
              " [46, 11],\n",
              " [46, 11, 47],\n",
              " [46, 11, 47, 48],\n",
              " [46, 11, 47, 48, 49],\n",
              " [46, 11, 47, 48, 49, 50],\n",
              " [46, 11, 47, 48, 49, 50, 8],\n",
              " [51, 2],\n",
              " [51, 2, 3],\n",
              " [51, 2, 3, 52],\n",
              " [51, 2, 3, 52, 4],\n",
              " [51, 2, 3, 52, 4, 53],\n",
              " [51, 2, 3, 52, 4, 53, 6],\n",
              " [51, 2, 3, 52, 4, 53, 6, 10],\n",
              " [54, 11],\n",
              " [54, 11, 55],\n",
              " [54, 11, 55, 56],\n",
              " [54, 11, 55, 56, 3],\n",
              " [54, 11, 55, 56, 3, 57],\n",
              " [54, 11, 55, 56, 3, 57, 58],\n",
              " [54, 11, 55, 56, 3, 57, 58, 59],\n",
              " [54, 11, 55, 56, 3, 57, 58, 59, 60],\n",
              " [1, 61],\n",
              " [1, 61, 2],\n",
              " [1, 61, 2, 62],\n",
              " [1, 61, 2, 62, 4],\n",
              " [1, 61, 2, 62, 4, 63],\n",
              " [1, 61, 2, 62, 4, 63, 64],\n",
              " [65, 66],\n",
              " [65, 66, 67],\n",
              " [65, 66, 67, 68],\n",
              " [65, 66, 67, 68, 1],\n",
              " [65, 66, 67, 68, 1, 69],\n",
              " [70, 71],\n",
              " [70, 71, 72],\n",
              " [70, 71, 72, 12],\n",
              " [70, 71, 72, 12, 9],\n",
              " [70, 71, 72, 12, 9, 4],\n",
              " [70, 71, 72, 12, 9, 4, 73],\n",
              " [74, 2],\n",
              " [74, 2, 75],\n",
              " [74, 2, 75, 76],\n",
              " [74, 2, 75, 76, 77],\n",
              " [74, 2, 75, 76, 77, 78],\n",
              " [74, 2, 75, 76, 77, 78, 79],\n",
              " [13, 80],\n",
              " [13, 80, 81],\n",
              " [13, 80, 81, 82],\n",
              " [13, 80, 81, 82, 1],\n",
              " [13, 80, 81, 82, 1, 83],\n",
              " [13, 80, 81, 82, 1, 83, 5],\n",
              " [13, 80, 81, 82, 1, 83, 5, 84],\n",
              " [85, 14],\n",
              " [85, 14, 86],\n",
              " [85, 14, 86, 3],\n",
              " [85, 14, 86, 3, 87],\n",
              " [85, 14, 86, 3, 87, 88],\n",
              " [85, 14, 86, 3, 87, 88, 5],\n",
              " [85, 14, 86, 3, 87, 88, 5, 12],\n",
              " [85, 14, 86, 3, 87, 88, 5, 12, 89],\n",
              " [1, 90],\n",
              " [1, 90, 91],\n",
              " [1, 90, 91, 5],\n",
              " [1, 90, 91, 5, 1],\n",
              " [1, 90, 91, 5, 1, 92],\n",
              " [1, 90, 91, 5, 1, 92, 4],\n",
              " [1, 90, 91, 5, 1, 92, 4, 93],\n",
              " [1, 90, 91, 5, 1, 92, 4, 93, 94],\n",
              " [1, 90, 91, 5, 1, 92, 4, 93, 94, 1],\n",
              " [1, 90, 91, 5, 1, 92, 4, 93, 94, 1, 95],\n",
              " [13, 96],\n",
              " [13, 96, 3],\n",
              " [13, 96, 3, 97],\n",
              " [13, 96, 3, 97, 98],\n",
              " [13, 96, 3, 97, 98, 14],\n",
              " [13, 96, 3, 97, 98, 14, 99],\n",
              " [13, 96, 3, 97, 98, 14, 99, 100],\n",
              " [13, 96, 3, 97, 98, 14, 99, 100, 101],\n",
              " [102, 103],\n",
              " [102, 103, 104],\n",
              " [102, 103, 104, 2],\n",
              " [102, 103, 104, 2, 105],\n",
              " [102, 103, 104, 2, 105, 106],\n",
              " [107, 2],\n",
              " [107, 2, 108],\n",
              " [107, 2, 108, 109],\n",
              " [107, 2, 108, 109, 3],\n",
              " [107, 2, 108, 109, 3, 110],\n",
              " [107, 2, 108, 109, 3, 110, 111],\n",
              " [112, 113],\n",
              " [112, 113, 7],\n",
              " [112, 113, 7, 114],\n",
              " [112, 113, 7, 114, 115],\n",
              " [112, 113, 7, 114, 115, 116],\n",
              " [112, 113, 7, 114, 115, 116, 117],\n",
              " [112, 113, 7, 114, 115, 116, 117, 118]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpWsoS8K_Jo4",
        "outputId": "befac8c4-b8ec-4d55-c4b2-604c6c31a9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "AJnt-xv4_Vn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "id": "Kqz7Bvfe_6Jx",
        "outputId": "31e9a1fc-f080-4696-f223-79a3c7e37869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   1,  15],\n",
              "       [  0,   0,   0, ...,   1,  15,  16],\n",
              "       [  0,   0,   0, ...,  15,  16,  17],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 114, 115, 116],\n",
              "       [  0,   0,   0, ..., 115, 116, 117],\n",
              "       [  0,   0,   0, ..., 116, 117, 118]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:, :-1]\n",
        "y = padded_input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "Z5ZbWEi7_nXe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by84QOUNByEp",
        "outputId": "55915eb6-80bb-4a3c-ebaa-c05254b4f03e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK7LYDaFBzSD",
        "outputId": "0ba99c03-adc5-4072-c10c-d06f973ada73"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n"
      ],
      "metadata": {
        "id": "RslRwouZB7v_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_C6MbiuCfIi",
        "outputId": "48e49f58-23e7-4181-f0b5-5f7b4ff62fae"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134, 119)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "3USZbBLUFZew"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))"
      ],
      "metadata": {
        "id": "FLjHPxTnFlD8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CyD_q8asHlhy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHihjJPnHqFm",
        "outputId": "e095c7f9-29ac-4c99-f2d4-fa10765c80d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 10, 100)           11900     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 119)               17969     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180469 (704.96 KB)\n",
            "Trainable params: 180469 (704.96 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rzrvqOqQiAe",
        "outputId": "fb530ef7-c39d-429d-b282-9bbf6b307a92"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 35ms/step - loss: 4.7790 - accuracy: 0.0149\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 4.7584 - accuracy: 0.0672\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 4.7298 - accuracy: 0.0597\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 4.6639 - accuracy: 0.0522\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 4.5490 - accuracy: 0.0522\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 4.5233 - accuracy: 0.0522\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 4.4612 - accuracy: 0.0522\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 4.4480 - accuracy: 0.0448\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 4.4211 - accuracy: 0.0448\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 4.3839 - accuracy: 0.0448\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.3921 - accuracy: 0.0746\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.3322 - accuracy: 0.1045\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 4.3048 - accuracy: 0.0597\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 4.2754 - accuracy: 0.0746\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 4.2350 - accuracy: 0.0821\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 4.1912 - accuracy: 0.1269\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 4.1365 - accuracy: 0.1567\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 4.0701 - accuracy: 0.1493\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.9844 - accuracy: 0.1418\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.8983 - accuracy: 0.1716\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.8071 - accuracy: 0.1716\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 3.7776 - accuracy: 0.1567\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 3.6912 - accuracy: 0.1716\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.5489 - accuracy: 0.1493\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.4438 - accuracy: 0.1791\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 3.3549 - accuracy: 0.2015\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 3.2052 - accuracy: 0.2090\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 3.1037 - accuracy: 0.2612\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.9832 - accuracy: 0.2910\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.8682 - accuracy: 0.3134\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.8002 - accuracy: 0.2985\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.6657 - accuracy: 0.3507\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.5644 - accuracy: 0.3806\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.4533 - accuracy: 0.4104\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.3622 - accuracy: 0.4254\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.2952 - accuracy: 0.4627\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.1946 - accuracy: 0.4925\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.1185 - accuracy: 0.4925\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.0122 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.9406 - accuracy: 0.5597\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.8920 - accuracy: 0.5821\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.8173 - accuracy: 0.5746\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.7847 - accuracy: 0.5522\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.7014 - accuracy: 0.5896\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.6694 - accuracy: 0.6194\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.5877 - accuracy: 0.6418\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.5544 - accuracy: 0.7015\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4947 - accuracy: 0.7015\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4578 - accuracy: 0.7388\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.4050 - accuracy: 0.6940\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3522 - accuracy: 0.7239\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.3163 - accuracy: 0.7612\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.2706 - accuracy: 0.7537\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.2248 - accuracy: 0.7537\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1787 - accuracy: 0.8060\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1495 - accuracy: 0.8134\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.1260 - accuracy: 0.8284\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0848 - accuracy: 0.7910\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.0412 - accuracy: 0.8284\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.0325 - accuracy: 0.8284\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9931 - accuracy: 0.8433\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.9578 - accuracy: 0.8657\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.9175 - accuracy: 0.8507\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9021 - accuracy: 0.8657\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8712 - accuracy: 0.8881\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8430 - accuracy: 0.8881\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.8162 - accuracy: 0.8955\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7969 - accuracy: 0.8881\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7699 - accuracy: 0.8806\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.7561 - accuracy: 0.8507\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.7260 - accuracy: 0.8806\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7055 - accuracy: 0.8806\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6877 - accuracy: 0.8806\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6614 - accuracy: 0.9030\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6403 - accuracy: 0.9328\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6267 - accuracy: 0.9254\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6070 - accuracy: 0.9328\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5951 - accuracy: 0.9403\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5949 - accuracy: 0.9552\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5765 - accuracy: 0.9478\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5499 - accuracy: 0.9403\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5440 - accuracy: 0.9254\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5250 - accuracy: 0.9328\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5134 - accuracy: 0.9254\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4925 - accuracy: 0.9403\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4717 - accuracy: 0.9478\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4554 - accuracy: 0.9552\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4454 - accuracy: 0.9627\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.4352 - accuracy: 0.9701\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4237 - accuracy: 0.9701\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4072 - accuracy: 0.9701\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3986 - accuracy: 0.9627\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3845 - accuracy: 0.9552\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3781 - accuracy: 0.9776\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3747 - accuracy: 0.9701\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3677 - accuracy: 0.9776\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3549 - accuracy: 0.9776\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.3449 - accuracy: 0.9701\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3362 - accuracy: 0.9701\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3231 - accuracy: 0.9776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a70caf47f70>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "qiE2GhF6R3p9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"the weather\"\n",
        "\n",
        "for i in range(5):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=max_len-1, padding='pre')\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      print(word)\n",
        "      text += \" \" + word\n",
        "      print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO0wRQJNRG_Q",
        "outputId": "d4240c61-b36a-41b9-ed13-d08834877c85"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "is\n",
            "the weather is\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "sunny\n",
            "the weather is sunny\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "and\n",
            "the weather is sunny and\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "warm\n",
            "the weather is sunny and warm\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "today\n",
            "the weather is sunny and warm today\n"
          ]
        }
      ]
    }
  ]
}